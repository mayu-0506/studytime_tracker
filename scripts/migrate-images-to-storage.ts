#!/usr/bin/env tsx
/**
 * Base64ç”»åƒã‚’Supabase Storageã«ç§»è¡Œã™ã‚‹Node.jsã‚¹ã‚¯ãƒªãƒ—ãƒˆ
 * ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ç”»åƒã‚’å–å¾—ã—ã¦Storageã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
 */

import { config } from 'dotenv'
import { createClient } from '@supabase/supabase-js'
import { writeFileSync, mkdirSync } from 'fs'
import { join } from 'path'

// ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
config({ path: '.env.local' })

// Supabase Admin Client
const supabaseAdmin = createClient(
  process.env.NEXT_PUBLIC_SUPABASE_URL!,
  process.env.SUPABASE_SERVICE_ROLE_KEY!,
  {
    auth: {
      autoRefreshToken: false,
      persistSession: false
    }
  }
)

interface BackupImage {
  user_id: string
  base64_image: string
  backed_up_at: string
}

interface MigrationResult {
  userId: string
  success: boolean
  error?: string
  storageUrl?: string
  imageSize?: number
}

/**
 * Base64ã‚’Bufferã«å¤‰æ›
 */
function base64ToBuffer(base64String: string): { buffer: Buffer; mimeType: string; extension: string } {
  // data:image/png;base64,iVBORw... ã®å½¢å¼ã‹ã‚‰æŠ½å‡º
  const matches = base64String.match(/^data:([A-Za-z-+\/]+);base64,(.+)$/)
  
  if (!matches || matches.length !== 3) {
    throw new Error('Invalid base64 string format')
  }
  
  const mimeType = matches[1]
  const base64Data = matches[2]
  const buffer = Buffer.from(base64Data, 'base64')
  
  // MIMEã‚¿ã‚¤ãƒ—ã‹ã‚‰æ‹¡å¼µå­ã‚’æ±ºå®š
  const extension = mimeType.split('/')[1] || 'png'
  
  return { buffer, mimeType, extension }
}

/**
 * ç”»åƒã‚’Supabase Storageã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
 */
async function uploadImageToStorage(
  userId: string,
  base64Image: string
): Promise<{ url: string; path: string }> {
  const { buffer, mimeType, extension } = base64ToBuffer(base64Image)
  
  // ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç”Ÿæˆ
  const timestamp = Date.now()
  const fileName = `${userId}_${timestamp}.${extension}`
  const filePath = `avatars/${fileName}`
  
  console.log(`ğŸ“¤ Uploading ${filePath} (${(buffer.length / 1024).toFixed(2)} KB)`)
  
  // Storageã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
  const { data, error } = await supabaseAdmin.storage
    .from('avatars')
    .upload(filePath, buffer, {
      contentType: mimeType,
      upsert: false,
      cacheControl: '3600'
    })
  
  if (error) {
    throw error
  }
  
  // å…¬é–‹URLã‚’å–å¾—
  const { data: { publicUrl } } = supabaseAdmin.storage
    .from('avatars')
    .getPublicUrl(filePath)
  
  return { url: publicUrl, path: filePath }
}

/**
 * ãƒ¡ã‚¤ãƒ³å‡¦ç†
 */
async function migrateImages() {
  console.log('ğŸš€ Starting image migration from backup table...')
  
  const results: MigrationResult[] = []
  const logDir = join(process.cwd(), 'logs')
  mkdirSync(logDir, { recursive: true })
  
  try {
    // ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ç”»åƒã‚’å–å¾—
    const { data: backups, error: fetchError } = await supabaseAdmin
      .from('user_image_backup')
      .select('*')
      .order('backed_up_at', { ascending: true })
    
    if (fetchError) {
      throw fetchError
    }
    
    if (!backups || backups.length === 0) {
      console.log('â„¹ï¸ No backup images found')
      return
    }
    
    console.log(`ğŸ“Š Found ${backups.length} images to migrate`)
    
    // å„ç”»åƒã‚’å‡¦ç†
    for (const backup of backups) {
      const result: MigrationResult = {
        userId: backup.user_id,
        success: false
      }
      
      try {
        // ç”»åƒã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
        const imageSize = backup.base64_image.length
        result.imageSize = imageSize
        
        console.log(`\nğŸ‘¤ Processing user: ${backup.user_id}`)
        console.log(`   Image size: ${(imageSize / 1024).toFixed(2)} KB`)
        
        // Storageã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
        const { url, path } = await uploadImageToStorage(
          backup.user_id,
          backup.base64_image
        )
        
        result.storageUrl = url
        
        // ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°
        const { error: updateError } = await supabaseAdmin.auth.admin.updateUserById(
          backup.user_id,
          {
            user_metadata: {
              avatar_url: url,
              avatar_path: path,
              image_migrated: true,
              migrated_at: new Date().toISOString()
            }
          }
        )
        
        if (updateError) {
          throw updateError
        }
        
        // æˆåŠŸå¾Œã€ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚’å‰Šé™¤ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        const { error: deleteError } = await supabaseAdmin
          .from('user_image_backup')
          .delete()
          .eq('user_id', backup.user_id)
        
        if (deleteError) {
          console.warn(`   âš ï¸ Failed to delete backup: ${deleteError.message}`)
        }
        
        result.success = true
        console.log(`   âœ… Successfully migrated to: ${url}`)
        
      } catch (error) {
        result.success = false
        result.error = error instanceof Error ? error.message : String(error)
        console.error(`   âŒ Error: ${result.error}`)
      }
      
      results.push(result)
    }
    
    // çµæœã‚’ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
    const logFile = join(logDir, `migration-${Date.now()}.json`)
    writeFileSync(logFile, JSON.stringify(results, null, 2))
    
    // ã‚µãƒãƒªãƒ¼
    const successful = results.filter(r => r.success).length
    const failed = results.filter(r => !r.success).length
    
    console.log('\nğŸ“Š Migration Summary:')
    console.log(`âœ… Successful: ${successful}`)
    console.log(`âŒ Failed: ${failed}`)
    console.log(`ğŸ“„ Log file: ${logFile}`)
    
    // å¤±æ•—ã—ãŸã‚‚ã®ã‚’è¡¨ç¤º
    if (failed > 0) {
      console.log('\nâŒ Failed migrations:')
      results
        .filter(r => !r.success)
        .forEach(r => {
          console.log(`- User ${r.userId}: ${r.error}`)
        })
    }
    
  } catch (error) {
    console.error('âŒ Migration failed:', error)
    process.exit(1)
  }
}

// ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ãƒã‚±ãƒƒãƒˆã®ä½œæˆç¢ºèª
async function ensureStorageBucket() {
  console.log('ğŸª£ Checking storage bucket...')
  
  const { data: buckets, error } = await supabaseAdmin.storage.listBuckets()
  
  if (error) {
    console.error('âŒ Failed to list buckets:', error)
    return false
  }
  
  const avatarBucket = buckets.find(b => b.name === 'avatars')
  
  if (!avatarBucket) {
    console.log('ğŸ“¦ Creating avatars bucket...')
    
    const { error: createError } = await supabaseAdmin.storage.createBucket('avatars', {
      public: true,
      allowedMimeTypes: ['image/jpeg', 'image/png', 'image/gif', 'image/webp']
    })
    
    if (createError) {
      console.error('âŒ Failed to create bucket:', createError)
      return false
    }
    
    console.log('âœ… Avatars bucket created')
  } else {
    console.log('âœ… Avatars bucket exists')
  }
  
  return true
}

// ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ
async function main() {
  // ç’°å¢ƒå¤‰æ•°ãƒã‚§ãƒƒã‚¯
  if (!process.env.SUPABASE_SERVICE_ROLE_KEY) {
    console.error('âŒ SUPABASE_SERVICE_ROLE_KEY is not set')
    process.exit(1)
  }
  
  // ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ãƒã‚±ãƒƒãƒˆç¢ºèª
  const bucketReady = await ensureStorageBucket()
  if (!bucketReady) {
    console.error('âŒ Storage bucket is not ready')
    process.exit(1)
  }
  
  // ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
  await migrateImages()
}

// ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
process.on('unhandledRejection', (error) => {
  console.error('âŒ Unhandled rejection:', error)
  process.exit(1)
})

main().catch(console.error)